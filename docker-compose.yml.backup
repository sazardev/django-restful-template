# ============================================================================
# DJANGO RESTFUL LOGISTICS TEMPLATE - PRODUCTION READY DOCKER COMPOSE
# ============================================================================
# Configuración "todo en uno" lista para producción
#
# QUICK START:
# 1. Copia .env.example a .env y configura las variables
# 2. Para entorno con datos de prueba: LOAD_TEST_DATA=true docker-compose up -d
# 3. Para entorno limpio: LOAD_TEST_DATA=false docker-compose up -d
# 4. Accede a: http://localhost (Nginx), http://localhost:5555/flower (Celery)
#
# SERVICIOS INCLUIDOS:
# - Django (Gunicorn + ASGI/Daphne para WebSocket)
# - PostgreSQL (Base de datos principal)
# - Redis (Cache + Message Broker)
# - Celery Worker + Beat (Tareas asíncronas)
# - Nginx (Reverse Proxy + Static Files)
# - Flower (Monitoreo de Celery)
# ============================================================================

services:
  # ============================================================================
  # NGINX - Reverse Proxy & Static Files
  # ============================================================================
  nginx:
    image: nginx:1.25-alpine
    container_name: logistics_nginx
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./nginx/nginx.conf:/etc/nginx/nginx.conf:ro
      - ./nginx/ssl:/etc/nginx/ssl:ro
      - static_volume:/var/www/staticfiles:ro
      - media_volume:/var/www/media:ro
      - ./logs/nginx:/var/log/nginx
    depends_on:
      web:
        condition: service_healthy
      websocket:
        condition: service_started
    restart: unless-stopped
    networks:
      - logistics_network
    healthcheck:
      test:
        [
          "CMD",
          "wget",
          "--quiet",
          "--tries=1",
          "--spider",
          "http://localhost/health/",
        ]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
  # ============================================================================
  # DJANGO WEB - Main Application (HTTP + API)
  # ============================================================================
  web:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: logistics_web
    command: >
      gunicorn config.wsgi:application
      --bind 0.0.0.0:8000
      --workers 4
      --worker-class gevent
      --worker-connections 1000
      --max-requests 1000
      --max-requests-jitter 50
          --timeout 30 \
          --keep-alive 2 \
          --log-level info \
          --access-logfile /app/logs/gunicorn-access.log \
          --error-logfile /app/logs/gunicorn-error.log \
          --capture-output
      "    volumes:
      - static_volume:/app/staticfiles
      - media_volume:/app/media
      - ./logs:/app/logs
    environment:
      - DJANGO_SETTINGS_MODULE=${DJANGO_SETTINGS_MODULE:-config.settings.base}
      - PYTHONUNBUFFERED=1
      - PYTHONDONTWRITEBYTECODE=1
      - LOAD_TEST_DATA=${LOAD_TEST_DATA:-false}
    env_file:
      - .env
    depends_on:
      db:
        condition: service_healthy
      redis:
        condition: service_healthy
    restart: unless-stopped
    networks:
      - logistics_network
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/api/health/"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s

  # ============================================================================
  # DJANGO WEBSOCKET - Real-time Communications (ASGI)
  # ============================================================================  websocket:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: logistics_websocket
    command: >
      daphne -b 0.0.0.0 -p 8001
      --verbosity 2
      --access-log /app/logs/daphne-access.log
      config.asgi:application
    volumes:
      - ./logs:/app/logs
    environment:
      - DJANGO_SETTINGS_MODULE=${DJANGO_SETTINGS_MODULE:-config.settings.base}
      - PYTHONUNBUFFERED=1
      - PYTHONDONTWRITEBYTECODE=1
    env_file:
      - .env
    depends_on:
      db:
        condition: service_healthy
      redis:
        condition: service_healthy
    restart: unless-stopped
    networks:
      - logistics_network
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8001/ws/health/"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s

  # ============================================================================
  # POSTGRESQL - Main Database
  # ============================================================================
  db:
    image: postgres:15-alpine
    container_name: logistics_postgres
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./postgres/init:/docker-entrypoint-initdb.d
      - ./logs/postgres:/var/log/postgresql
    environment:
      - POSTGRES_DB=${DATABASE_NAME:-logistics_db}
      - POSTGRES_USER=${DATABASE_USER:-logistics_user}
      - POSTGRES_PASSWORD=${DATABASE_PASSWORD:-secure_password}
      - POSTGRES_INITDB_ARGS=--encoding=UTF-8 --lc-collate=en_US.UTF-8 --lc-ctype=en_US.UTF-8
      - PGDATA=/var/lib/postgresql/data/pgdata
    ports:
      - "${DATABASE_PORT:-5432}:5432"
    restart: unless-stopped
    networks:
      - logistics_network
    healthcheck:
      test:
        [
          "CMD-SHELL",
          "pg_isready -U ${DATABASE_USER:-logistics_user} -d ${DATABASE_NAME:-logistics_db}",
        ]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 30s
    command: |
      postgres -c 'max_connections=200'
               -c 'shared_buffers=256MB'
               -c 'effective_cache_size=1GB'
               -c 'work_mem=4MB'
               -c 'maintenance_work_mem=64MB'
               -c 'random_page_cost=1.1'
               -c 'temp_file_limit=2GB'
               -c 'log_min_duration_statement=1000'
               -c 'idle_in_transaction_session_timeout=10min'
               -c 'lock_timeout=1min'
               -c 'statement_timeout=10min'

  # ============================================================================
  # REDIS - Cache & Message Broker
  # ============================================================================
  redis:
    image: redis:7-alpine
    container_name: logistics_redis
    volumes:
      - redis_data:/data
      - ./redis/redis.conf:/usr/local/etc/redis/redis.conf:ro
    ports:
      - "${REDIS_PORT:-6379}:6379"
    command: redis-server /usr/local/etc/redis/redis.conf --appendonly yes
    restart: unless-stopped
    networks:
      - logistics_network
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 30s
    sysctls:
      - net.core.somaxconn=65535

  # ============================================================================
  # CELERY WORKER - Background Tasks
  # ============================================================================  celery:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: logistics_celery
    command: >
      celery -A config worker
      --loglevel=info
      --concurrency=4
      --prefetch-multiplier=1
      --max-tasks-per-child=1000
      --logfile=/app/logs/celery-worker.log
      --hostname=worker@%h
    volumes:
      - ./logs:/app/logs
      - media_volume:/app/media
    environment:
      - DJANGO_SETTINGS_MODULE=${DJANGO_SETTINGS_MODULE:-config.settings.base}
      - PYTHONUNBUFFERED=1
      - PYTHONDONTWRITEBYTECODE=1
      - C_FORCE_ROOT=1
    env_file:
      - .env
    depends_on:
      db:
        condition: service_healthy
      redis:
        condition: service_healthy
    restart: unless-stopped
    networks:
      - logistics_network
    healthcheck:
      test: ["CMD", "celery", "-A", "config", "inspect", "ping"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s

  # ============================================================================
  # CELERY BEAT - Task Scheduler
  # ============================================================================  celery-beat:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: logistics_celery_beat
    command: >
      celery -A config beat
      --loglevel=info
      --scheduler django_celery_beat.schedulers:DatabaseScheduler
      --logfile=/app/logs/celery-beat.log
      --pidfile=/tmp/celerybeat.pid
    volumes:
      - ./logs:/app/logs
    environment:
      - DJANGO_SETTINGS_MODULE=${DJANGO_SETTINGS_MODULE:-config.settings.base}
      - PYTHONUNBUFFERED=1
      - PYTHONDONTWRITEBYTECODE=1
    env_file:
      - .env
    depends_on:
      db:
        condition: service_healthy
      redis:
        condition: service_healthy
    restart: unless-stopped
    networks:
      - logistics_network

  # ============================================================================
  # FLOWER - Celery Monitoring
  # ============================================================================  flower:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: logistics_flower
    command: >
      celery -A config flower
      --port=5555
      --basic_auth=${FLOWER_USER:-admin}:${FLOWER_PASSWORD:-flower123}
      --url_prefix=flower
      --persistent=True
      --db=/app/logs/flower.db
      --logfile=/app/logs/flower.log
    ports:
      - "5555:5555"
    volumes:
      - ./logs:/app/logs
    environment:
      - DJANGO_SETTINGS_MODULE=${DJANGO_SETTINGS_MODULE:-config.settings.base}
      - PYTHONUNBUFFERED=1
    env_file:
      - .env
    depends_on:
      redis:
        condition: service_healthy
    restart: unless-stopped
    networks:
      - logistics_network

# ============================================================================
# VOLUMES
# ============================================================================
volumes:
  postgres_data:
    driver: local
  redis_data:
    driver: local
  static_volume:
    driver: local
  media_volume:
    driver: local

# ============================================================================
# NETWORKS
# ============================================================================
networks:
  logistics_network:
    driver: bridge
    ipam:
      config:
        - subnet: 172.20.0.0/16
